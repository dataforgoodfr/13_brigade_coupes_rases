# Custom code derived from Yoann Crouin's written code.
# link --> https://github.com/dataforgoodfr/13_brigade_coupes_rases/blob/main/analytics/notebooks/prepare_sufosat_v3_layer.py
# # -*- coding: utf-8 -*-
from typing import cast

import geopandas as gpd
import pandas as pd
from tqdm import tqdm
from utils.disjoin_set import DisjointSet
from utils.logging_etl import etl_logger


class PreparePolygon:
    def __init__(self):
        self.logger = etl_logger("logs/transform.log")
        self.disjoin_set = DisjointSet

    def parse_sufosat_date(self, sufosat_date: float) -> pd.Timestamp:
        """
        Converts SUFOSAT date format to a pandas Timestamp.

        The input format is YYDDD, where YY is the year (e.g., 18-25 = 2018-2025)
        and DDD is the day of the year (1-366).

        Parameters
        ----------
        sufosat_date : float
            Date in SUFOSAT format (YYDDD).

        Returns
        -------
        pd.Timestamp
            Converted date as a pandas Timestamp.

        Examples
        --------
        ->>> parse_sufosat_date(19032)
        Timestamp('2019-02-01 00:00:00')  # February 1, 2019 (32nd day of 2019)
        """

        sufosat_date = int(sufosat_date)
        return pd.Timestamp(
            year=2000 + sufosat_date // 1000, month=1, day=1
        ) + pd.Timedelta(days=(sufosat_date % 1000) - 1)

    def pair_clear_cuts_through_space_and_time(
        self,
        gdf: gpd.GeoDataFrame,
        max_meters_between_clear_cuts: int,
        max_days_between_clear_cuts: int,
    ) -> pd.DataFrame:
        """
        Identifies pairs of clear-cuts that are within a specified distance and a
        specified number of days of each other.

        Parameters
        ----------
        gdf : gpd.GeoDataFrame
            GeoDataFrame containing clear-cut polygons with a 'geometry' column.
        max_meters_between_clear_cuts : int
            Maximum distance in meters that can separate two clear-cuts for them
            to be considered a pair.
        max_days_between_clear_cuts : int
            Maximum time difference in days between clear-cuts to consider them related.


        Returns
        -------
        pd.DataFrame
            DataFrame with columns:
            - index_left: Index of the first clear-cut in each pair
            - date_left: Date of the first clear-cut
            - index_right: Index of the second clear-cut in each pair
            - date_right: Date of the second clear-cut

        Notes
        -----
        This function can consume a significant amount of memory due to the Cartesian product
        generated by the spatial join.
        """
        self.logger.info(
            f"Pairing clear-cuts within {max_meters_between_clear_cuts} meters "
            f"and {max_days_between_clear_cuts} days of each other"
        )

        # Cluster the clear-cuts that are within `max_meters_between_clear_cuts` of each other
        # Lambert-93 CRS uses meters as its unit of measurement for distance.
        clear_cut_pairs: pd.DataFrame = (
            gdf.sjoin(
                gdf,
                how="left",
                predicate="dwithin",
                distance=max_meters_between_clear_cuts,
            )
            .reset_index()
            .rename(columns={"index": "index_left"})
        )

        # Ignore clear-cuts that intersect with themselves
        clear_cut_pairs = clear_cut_pairs[
            clear_cut_pairs["index_left"] != clear_cut_pairs["index_right"]
        ]

        # Remove duplicates (left -> right exists, ignore right -> left)
        clear_cut_pairs = clear_cut_pairs[
            clear_cut_pairs["index_left"] < clear_cut_pairs["index_right"]
        ]

        # Remove pairs if the date difference is too big
        clear_cut_pairs = clear_cut_pairs[
            (clear_cut_pairs["date_left"] - clear_cut_pairs["date_right"]).dt.days.abs()
            <= max_days_between_clear_cuts
        ]

        self.logger.info(
            f"Found {len(clear_cut_pairs)} potential clear-cut pairs (before shape complexity filtering)"
        )

        return clear_cut_pairs

    def regroup_clear_cut_pairs(self, clear_cut_pairs: pd.DataFrame) -> list[set[int]]:
        """
        Groups connected clear-cut pairs into distinct sets (clusters).

        Given a set of identified clear-cut pairs, this function groups all
        interconnected clear cuts into the same set using a disjoint-set
        data structure (also known as a union-find algorithm).

        Parameters
        ----------
        clear_cut_pairs : pd.DataFrame
            DataFrame containing pairs of clear-cut IDs that are connected,
            with columns 'index_left' and 'index_right'.

        Returns
        -------
        list[set[int]]
            A list of sets, where each set contains the IDs of clear cuts
            belonging to the same cluster.

        Examples
        --------
        If we have four clear cuts (A, B, C, and D) and the identified pairs
        are (A, B) and (B, D), the function will group them as:
        - Group 1: {A, B, D}
        - Group 2: {C}
        """
        self.logger.info("Grouping connected clear-cuts into clusters")

        # Get all unique clear-cut indices from both columns
        all_indices = pd.concat(
            [clear_cut_pairs["index_left"], clear_cut_pairs["index_right"]]
        ).unique()

        # Start with each clear cut having its own group
        clear_cuts_disjoint_set = self.disjoin_set(all_indices)

        # Group the clear cuts that belong together one pair at a time
        for index_left, index_right in tqdm(
            clear_cut_pairs[["index_left", "index_right"]].itertuples(index=False),
            total=len(clear_cut_pairs),
            desc="Merging connected clear-cuts",
        ):
            clear_cuts_disjoint_set.merge(index_left, index_right)

        # Get the resulting subsets (clusters)
        subsets = cast(list[set[int]], clear_cuts_disjoint_set.subsets())

        self.logger.info(f"Created {len(subsets)} clear-cut clusters")

        return subsets

    def cluster_clear_cuts(
        self,
        gdf: gpd.GeoDataFrame,
        max_meters_between_clear_cuts: int,
        max_days_between_clear_cuts: int,
    ) -> gpd.GeoDataFrame:
        """
        Clusters individual clear-cuts based on spatial and temporal proximity.
        Parameters
        ----------
        gdf : gpd.GeoDataFrame
            GeoDataFrame containing clear-cut polygons with 'date' and 'geometry' columns.
        max_meters_between_clear_cuts : int
            Maximum distance in meters between clear-cuts to consider them related.
        max_days_between_clear_cuts : int
            Maximum time difference in days between clear-cuts to consider them related.

        Returns
        -------
        gpd.GeoDataFrame
            The input GeoDataFrame with an additional 'clear_cut_group' column
            that assigns each polygon to a cluster.

        Notes
        -----
        The function modifies the input GeoDataFrame by adding a 'clear_cut_group' column.
        """
        self.logger.info("Clustering clear-cuts by spatial and temporal proximity")

        # Identify the clear cut groups
        clear_cut_pairs = self.pair_clear_cuts_through_space_and_time(
            gdf, max_meters_between_clear_cuts, max_days_between_clear_cuts
        )
        clear_cut_groups = self.regroup_clear_cut_pairs(clear_cut_pairs)

        # Assign a clear cut group id to each clear cut polygon
        self.logger.info("Assigning cluster IDs to clear-cuts")
        for i, subset in tqdm(
            enumerate(clear_cut_groups),
            total=len(clear_cut_groups),
            desc="Assigning cluster IDs",
        ):
            gdf.loc[list(subset), "clear_cut_group"] = i

        # Assign a cluster ID to the pixels that weren't grouped,
        # auto-incrementing from the last cluster ID
        gdf["clear_cut_group"] = gdf["clear_cut_group"].fillna(
            gdf["clear_cut_group"].max() + gdf["clear_cut_group"].isna().cumsum()
        )
        gdf["clear_cut_group"] = gdf["clear_cut_group"].astype(int)

        pixels_per_cluster = gdf.groupby("clear_cut_group").size()
        self.logger.info(
            "Clustering complete:\n"
            f"- Number of clusters: {gdf['clear_cut_group'].nunique()}\n"
            f"- Number of clusters with more than one pixel: {(pixels_per_cluster > 1).sum()}\n"
            f"- Number of clusters with a single pixel: {(pixels_per_cluster == 1).sum()}\n"
            f"- Min cluster ID: {gdf['clear_cut_group'].min()}\n"
            f"- Max cluster ID: {gdf['clear_cut_group'].max()}"
        )

        return gdf

    def union_clear_cut_clusters(self, gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        """
        Combines clear-cuts belonging to the same cluster into single geometries.

        This function dissolves the geometries based on the 'clear_cut_group' column,
        and calculates aggregate statistics for each cluster.

        Parameters
        ----------
        gdf : gpd.GeoDataFrame
            GeoDataFrame with 'clear_cut_group', 'date', and 'geometry' columns.

        Returns
        -------
        gpd.GeoDataFrame
            A new GeoDataFrame with one row per cluster, containing:
            - Unified geometry
            - Minimum and maximum dates
            - Time span of the cluster in days
            - Number of clear-cuts in each cluster
        """
        self.logger.info("Merging clear-cuts within each cluster")

        # Calculate group sizes before dissolve
        clear_cut_group_size = gdf.groupby("clear_cut_group").size()

        self.logger.info("Performing spatial union of geometries within each cluster")
        gdf = gdf.dissolve(
            by="clear_cut_group", aggfunc={"date": ["min", "max"]}
        ).rename(
            columns={
                ("date", "min"): "date_min",
                ("date", "max"): "date_max",
            }
        )
        gdf["days_delta"] = (gdf["date_max"] - gdf["date_min"]).dt.days
        gdf["clear_cut_group_size"] = clear_cut_group_size

        # Fill tiny gaps left after the dissolve/union operation
        self.logger.info("Filling tiny gaps in the dissolved geometries")
        gdf["geometry"] = gdf["geometry"].buffer(0.0001)

        self.logger.info(f"Successfully created {len(gdf)} merged clear-cut clusters")

        return gdf

    def add_concave_hull_score(
        self, gdf: gpd.GeoDataFrame, concave_hull_ratio: float
    ) -> gpd.GeoDataFrame:
        """
        Help identify the clear-cuts with complex shapes that may represent false positives.

        This function uses the concave hull score (ratio of the area of the shape to the
        area of its concave hull) to identify shapes that are too complex.

        Parameters
        ----------
        gdf : gpd.GeoDataFrame
            GeoDataFrame containing clear-cut polygons.
        concave_hull_ratio : float
            Ratio parameter for the concave hull calculation (1.0 = convex hull).
            Lower values create tighter hulls that follow the shape more closely.

        Returns
        -------
        gpd.GeoDataFrame
            GeoDataFrame with complex shapes tagged.

        Notes
        -----
        The concave hull score (area of polygon / area of concave hull) provides a measure
        of shape complexity. Values close to 0 indicate more complex, irregular shapes,
        while large values indicate simpler shapes. We clip the max score to 1.
        """
        self.logger.info('Adding the "concave_hull_score" column')

        # concave_hull(ratio=1) would be the same as convex_hull
        gdf["concave_hull_score"] = gdf.area / gdf.concave_hull(concave_hull_ratio).area
        # The score can be greater than 1 but we can clip it to [0, 1] for simplicity
        gdf["concave_hull_score"] = gdf["concave_hull_score"].clip(upper=1)

        # display_df(gdf)

        return gdf

    def add_area_ha(self, gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        # Add clear cut area, with 1 hectare = 10,000 m²
        self.logger.info("Adding clear-cut clusters area")
        gdf["area_ha"] = gdf.area / 10000

        # Let's sort the clear-cut clusters by their area
        gdf = gdf.sort_values("area_ha")

        self.logger.info(
            f"We identified {(gdf['area_ha'] >= 10).sum()} clear-cut clusters >= 10 ha"
        )

        return gdf
