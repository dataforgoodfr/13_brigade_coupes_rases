{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Process and upload Natura 2000 data\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from utils import download_file, S3Manager\n",
    "from pyproj import CRS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_SIC_N2000 = \"https://inpn.mnhn.fr/docs/Shape/sic.zip\"\n",
    "SIC_N2000 = \"../data/Natura_2000/sic.zip\"\n",
    "\n",
    "URL_ZPS_N2000 = \"https://inpn.mnhn.fr/docs/Shape/zps.zip\"\n",
    "ZPS_N2000 = \"../data/Natura_2000/zps.zip\"\n",
    "\n",
    "UPLOAD_TO_S3 = False\n",
    "LOCAL_FOLDER = \"../data/Natura_2000/\"\n",
    "OUTPUT_N2000_PARQUET = \"Merged_n2000.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize s3 manager\n",
    "s3_manager = S3Manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and processing of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sites classés au titre de la Directive Habitats : périmètres transmis à la CE (ZSC/pSIC/SIC)\"\n",
    "if os.path.exists(SIC_N2000):\n",
    "    nat2000_sic = gpd.read_file(SIC_N2000)\n",
    "else:\n",
    "    download_file(url=URL_SIC_N2000, save_path=SIC_N2000)\n",
    "    nat2000_sic = gpd.read_file(SIC_N2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Zones de protection spéciale (ZPS)\"\n",
    "if os.path.exists(ZPS_N2000):\n",
    "    nat2000_zps = gpd.read_file(ZPS_N2000)\n",
    "else:\n",
    "    download_file(url=URL_ZPS_N2000, save_path=ZPS_N2000)\n",
    "    nat2000_zps = gpd.read_file(ZPS_N2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging both overlapping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat2000 = gpd.GeoDataFrame(\n",
    "    geometry=[pd.concat([nat2000_sic, nat2000_zps]).union_all()], crs=nat2000_sic.crs\n",
    ")\n",
    "# Explode the multipolygon to get the individual polygons (one for each site)\n",
    "nat2000 = nat2000.explode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion tests and upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification du CRS\n",
    "assert CRS(nat2000.crs).to_epsg() == 2154, \"Le CRS du fichier Natura 2000 n'est pas EPSG:2154\"\n",
    "\n",
    "# Vérification des colonnes\n",
    "assert list(nat2000.columns) == [\"geometry\"], (\n",
    "    \"Le dataframe doit contenir uniquement une colonne 'geometry'\"\n",
    ")\n",
    "\n",
    "# Définition du chemin de sauvegarde\n",
    "local_file = os.path.join(LOCAL_FOLDER, OUTPUT_N2000_PARQUET)\n",
    "\n",
    "# Sauvegarde au format Parquet avec gestion des erreurs\n",
    "try:\n",
    "    nat2000.to_parquet(local_file)\n",
    "except Exception as e:\n",
    "    RuntimeError(f\"Échec de l'enregistrement du fichier {local_file}: {e}\")\n",
    "\n",
    "# Upload vers S3 si activé et si le fichier existe\n",
    "if UPLOAD_TO_S3:\n",
    "    if os.path.exists(local_file):\n",
    "        s3_manager.upload_to_s3(\n",
    "            file_path=local_file, s3_key=os.path.join(\"static_layers\", OUTPUT_N2000_PARQUET)\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Le fichier {local_file} n'existe pas, upload annulé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
