{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2afd68d0-b26e-434b-a5c4-161629f2e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from numpy.typing import NDArray\n",
    "from osgeo import gdal, ogr, osr\n",
    "from pyproj import Transformer\n",
    "from rasterio.windows import from_bounds\n",
    "from shapely import Point, box\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from typing import List\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7a392d-7929-4c1c-80a5-ea0da9a7c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook variables\n",
    "INPUT_RASTER_DATES = \"../data/sufosat/mosaics_tropisco_warnings_france_date.tif\"\n",
    "INPUT_RASTER_PROBAS = \"../data/sufosat/mosaics_tropisco_warnings_france_prob.tif\"\n",
    "OUTPUT_LAYER = \"../data/sufosat/sufosat_clear_cuts_2024.fgb\"\n",
    "SUFOSAT_START_DATE = pd.Timestamp(year=2014, month=4, day=3)\n",
    "START_DATE_CUTOFF = pd.Timestamp(year=2024, month=1, day=1)\n",
    "MAX_METERS_BETWEEN_CLEAR_CUTS = 50\n",
    "MAX_DAYS_BETWEEN_CLEAR_CUTS = 7 * 4\n",
    "MAGIC_NUMBER = 0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427756c-b3a3-452f-8bb4-4c5bfbe3bc43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Download from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0faa376-fc87-4bb3-9833-a7f5366d91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-25 08:31:33   96946219 analytics/data\n",
      "2025-03-02 18:58:22  114393184 analytics/data/abusive_clear_cuts/abusive_clear_cuts_2024.fgb\n",
      "2025-03-02 17:53:00  517567704 analytics/data/cadastre/cadastre_france_cities.fgb\n",
      "2025-03-02 17:53:03   28085888 analytics/data/cadastre/cadastre_france_departments.fgb\n",
      "2025-02-21 17:43:11  558882864 analytics/data/ign/bdalti25/slope_gte_30.fgb\n",
      "2025-02-21 17:42:55   32993275 analytics/data/ign/bdalti25/slope_gte_30.tif\n",
      "2025-02-25 08:58:17   96946219 analytics/data/sufosat/mosaics_tropisco_warnings_france_date.tif\n",
      "2025-02-25 09:08:57   76601154 analytics/data/sufosat/mosaics_tropisco_warnings_france_prob.tif\n",
      "2025-02-21 12:26:51  120737768 analytics/data/sufosat/sufosat_clear_cuts_2024.fgb\n",
      "2025-02-24 20:41:39          5 data/natura2000/Natura2000.cpg\n",
      "2025-02-24 20:41:39     613370 data/natura2000/Natura2000.dbf\n",
      "2025-02-24 20:41:39        452 data/natura2000/Natura2000.prj\n",
      "2025-02-24 20:42:23   87222536 data/natura2000/Natura2000.shp\n",
      "2025-02-24 20:41:39      14196 data/natura2000/Natura2000.shx\n",
      "2025-03-06 10:29:44   96946219 dataeng/sufosat_data/mosaics_tropisco_warnings_france_date.tif\n",
      "2025-03-06 10:29:48        500 dataeng/sufosat_data/mosaics_tropisco_warnings_france_date_metadata.json\n",
      "2025-03-06 10:36:52   89978775 dataeng/to_api/clear_cut_processed.geoparquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://brigade-coupe-rase-s3/ --recursive --profile d4g-s13-brigade-coupes-rases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1330103e-d561-4c6b-a4f4-f936495fb450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://brigade-coupe-rase-s3/analytics/data/ign/bdalti25/slope_gte_30.tif to ../data/ign/bdalti25/slope_gte_30.tif\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/cadastre/cadastre_france_departments.fgb to ../data/cadastre/cadastre_france_departments.fgb\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/sufosat/mosaics_tropisco_warnings_france_prob.tif to ../data/sufosat/mosaics_tropisco_warnings_france_prob.tif\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/abusive_clear_cuts/abusive_clear_cuts_2024.fgb to ../data/abusive_clear_cuts/abusive_clear_cuts_2024.fgb\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/sufosat/mosaics_tropisco_warnings_france_date.tif to ../data/sufosat/mosaics_tropisco_warnings_france_date.tif\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/ign/bdalti25/slope_gte_30.fgb to ../data/ign/bdalti25/slope_gte_30.fgb\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/sufosat/sufosat_clear_cuts_2024.fgb to ../data/sufosat/sufosat_clear_cuts_2024.fgb\n",
      "download: s3://brigade-coupe-rase-s3/analytics/data/cadastre/cadastre_france_cities.fgb to ../data/cadastre/cadastre_france_cities.fgb\n",
      "download: s3://brigade-coupe-rase-s3/data/natura2000/Natura2000.cpg to ../data/natura2000/Natura2000.cpg\n",
      "download: s3://brigade-coupe-rase-s3/data/natura2000/Natura2000.shx to ../data/natura2000/Natura2000.shx\n",
      "download: s3://brigade-coupe-rase-s3/data/natura2000/Natura2000.prj to ../data/natura2000/Natura2000.prj\n",
      "download: s3://brigade-coupe-rase-s3/data/natura2000/Natura2000.dbf to ../data/natura2000/Natura2000.dbf\n",
      "download: s3://brigade-coupe-rase-s3/data/natura2000/Natura2000.shp to ../data/natura2000/Natura2000.shp\n"
     ]
    }
   ],
   "source": [
    "# Download from s3\n",
    "!aws s3 cp --recursive s3://brigade-coupe-rase-s3/analytics/data ../data --profile d4g-s13-brigade-coupes-rases\n",
    "!aws s3 cp --recursive s3://brigade-coupe-rase-s3/data/natura2000 ../data/natura2000 --profile d4g-s13-brigade-coupes-rases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19be29-376c-4d2b-8f03-816d8e95adb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa40d577-7a16-4f22-babb-90f2f0cf3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "clearcuts: gpd.GeoDataFrame = gpd.read_file(\"../data/abusive_clear_cuts/abusive_clear_cuts_2024.fgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc04e040-31c7-438d-9695-65da0b323293",
   "metadata": {},
   "outputs": [],
   "source": [
    "abusive_clearcuts: gpd.GeoDataFrame = clearcuts[\n",
    "    (clearcuts[\"area_ha\"] >= 10)\n",
    "    | (clearcuts[\"natura2000_area_ha\"] >= 2)\n",
    "    | (clearcuts[\"slope30_area_ha\"] >= 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f0140a-0a5c-49c2-9ef4-14fc35dbea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "communes: gpd.GeoDataFrame = gpd.read_file(\"../data/cadastre/cadastre_france_cities.fgb\")\n",
    "departements: gpd.GeoDataFrame = gpd.read_file(\"../data/cadastre/cadastre_france_departments.fgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c462d-1232-4ffa-81b0-45006d18461d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6b3c447-1c7d-4a9a-b705-364cfa3ca188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_raster_subset(\n",
    "    raster_path: str,\n",
    "    minx: float,\n",
    "    maxx: float,\n",
    "    miny: float,\n",
    "    maxy: float,\n",
    "    min_date: pd.Timestamp | None = None,\n",
    ") -> tuple[NDArray[np.floating], tuple[float]]:\n",
    "    # Load a subset of a raster file based on given bounds.\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        window = from_bounds(\n",
    "            left=minx, bottom=miny, right=maxx, top=maxy, transform=src.transform\n",
    "        )\n",
    "        data = src.read(1, window=window)\n",
    "\n",
    "        # Get updated transform for the subset\n",
    "        transform = src.window_transform(window)\n",
    "\n",
    "    # Remove dates prior to min_date\n",
    "    if min_date:\n",
    "        data[data < (min_date - SUFOSAT_START_DATE).days] = src.nodata\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    data = data.astype(float)\n",
    "    data[data == 0] = np.nan\n",
    "\n",
    "    # Compute extent for imshow\n",
    "    left, top = transform * (0, 0)  # Upper-left corner in world coordinates\n",
    "    right, bottom = transform * (data.shape[1], data.shape[0])  # Lower-right corner\n",
    "    extent = (left, right, bottom, top)\n",
    "\n",
    "    return data, extent\n",
    "\n",
    "\n",
    "def plot_raster_dates(\n",
    "    data: NDArray[np.floating], extent: tuple[float], image_path: str, clear_cut: gpd.GeoDataFrame | None = None\n",
    ") -> None:\n",
    "    # Set up color mapping\n",
    "    categories_thresholds = np.unique(data[~np.isnan(data)])\n",
    "    if len(categories_thresholds) < 2:\n",
    "        categories_thresholds = np.array(\n",
    "            [categories_thresholds[0] - 1, categories_thresholds[0] + 1]\n",
    "        )\n",
    "    # Use the recommended way to get colormap\n",
    "    cmap = plt.colormaps[\"viridis\"].resampled(len(categories_thresholds))\n",
    "    norm = BoundaryNorm(boundaries=categories_thresholds, ncolors=len(categories_thresholds))\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "    img = ax.imshow(data, cmap=cmap, norm=norm, extent=extent)\n",
    "\n",
    "    # Configure colorbar with dates\n",
    "    cbar = plt.colorbar(img)\n",
    "    tick_values = cbar.get_ticks()\n",
    "    tick_labels = [\n",
    "        (SUFOSAT_START_DATE + pd.Timedelta(days=int(tick))).strftime(\"%Y-%m-%d\")\n",
    "        for tick in tick_values\n",
    "    ]\n",
    "\n",
    "    cbar.set_ticks(tick_values)\n",
    "    cbar.set_ticklabels(tick_labels)\n",
    "    cbar.set_label(\"Date\")\n",
    "\n",
    "    # Plot the clear cut polygon\n",
    "    if clear_cut is not None:\n",
    "        clear_cut.to_crs(epsg=4326).plot(ax=ax, facecolor=\"none\", edgecolor=\"red\", linewidth=1)\n",
    "\n",
    "    plt.title(\"SUFOSAT clear cut dates\")\n",
    "    # plt.show()\n",
    "    # Save the plot to a JPG file\n",
    "    plt.savefig(image_path, format=\"jpg\")\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cda1c0ab-8aa1-43fb-a109-ce3185acff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(gdf_group: gpd.GeoDataFrame, long: float, lat: float, image_path: str) -> None:\n",
    "    # Convert longitude and latitude from WGS84 (EPSG:4326) to Lambert 93 (EPSG:2154)\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:2154\", always_xy=True)\n",
    "    point = Point(transformer.transform(long, lat))\n",
    "    clear_cut = gdf_group[gdf_group.contains(point)]\n",
    "\n",
    "    # Plot the raster data (maybe we could overlay both in one plot)\n",
    "    minx, miny, maxx, maxy = clear_cut.to_crs(epsg=4326).geometry.bounds.iloc[0].tolist()\n",
    "    data, extent = load_raster_subset(\n",
    "        raster_path=INPUT_RASTER_DATES,\n",
    "        minx=minx,\n",
    "        miny=miny,\n",
    "        maxx=maxx,\n",
    "        maxy=maxy,\n",
    "        min_date=START_DATE_CUTOFF,\n",
    "    )\n",
    "    plot_raster_dates(data, extent, image_path, clear_cut)\n",
    "\n",
    "def get_links(long: float, lat: float) -> List[str]:\n",
    "    return [f\"https://browser.dataspace.copernicus.eu/?zoom=17&lat={lat}&lng={long}\",\n",
    "            f\"https://www.google.com/maps?q={lat},{long}\"]\n",
    "\n",
    "def get_image(gdf_group: gpd.GeoDataFrame, long: float, lat: float, image_name: str, image_path: str):\n",
    "    \"\"\"\n",
    "    Generates a graph using matplotlib, saves it as a JPG file, and returns an HTML <img> tag.\n",
    "\n",
    "    Parameters:\n",
    "        row (Pandas Series): The row from the DataFrame used to generate the graph.\n",
    "        image_path (str): The path where the JPG image will be saved.\n",
    "\n",
    "    Returns:\n",
    "        str: An HTML <img> tag pointing to the saved image.\n",
    "    \"\"\"\n",
    "    plot_example(gdf_group, long, lat, image_path+image_name)\n",
    "\n",
    "\n",
    "    # Return an HTML <img> tag pointing to the saved image\n",
    "    return f'<img src=\"{image_name}\" alt=\"Graph\" width=\"600\">'\n",
    "\n",
    "def generate_html_section(df, section_title, long_column=\"x\", lat_column=\"y\", output_path=''):\n",
    "    html_content = f\"\"\"\n",
    "        <h1>{section_title}</h1>\n",
    "    \"\"\"\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for row_id, row in df.iterrows():\n",
    "        # Generate URL and image using the provided functions\n",
    "        urls = get_links(row[long_column], row[lat_column])\n",
    "        image = get_image(df, row[long_column], row[lat_column], f\"plot{row_id}.jpg\", output_path)\n",
    "\n",
    "        # Add a row to the HTML content\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"row\">\n",
    "            <div class=\"id\">{row_id}</div>\n",
    "            <div class=\"field\">Date de début: {row['Date de début']}</div>\n",
    "            <div class=\"field\">Date de fin: {row['Date de fin']}</div>\n",
    "            <div class=\"field\">Durée (j): {row['Durée (j)']}</div>\n",
    "            <div class=\"field\">Aire (ha): {row['Aire (ha)']}</div>\n",
    "            <div class=\"field\">Aire Natura2000 (ha): {row['Aire Natura2000 (ha)']}</div>\n",
    "            <div class=\"field\">Aire pente >30% (ha): {row['Aire pente >30% (ha)']}</div>\n",
    "            <div class=\"field\">Commune: {row['Commune']}</div>\n",
    "            <div class=\"field\">Département: {row['Département']}</div>\n",
    "            <div class=\"field\">Longitude: {row['Longitude']}</div>\n",
    "            <div class=\"field\">Latitude: {row['Latitude']}</div>\n",
    "            <div class=\"link\"><a href=\"{urls[0]}\" target=\"_blank\">{urls[0]}</a></div>\n",
    "            <div class=\"link\"><a href=\"{urls[1]}\" target=\"_blank\">{urls[1]}</a></div>\n",
    "            <div class=\"image\">{image}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    return html_content\n",
    "\n",
    "def generate_html_page(df, long_column=\"x\", lat_column=\"y\", output_file=\"output.html\", output_path=\"\"):\n",
    "    \"\"\"\n",
    "    Generates an HTML page from a GeoPandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (GeoDataFrame): The input GeoPandas DataFrame.\n",
    "        long_column (str): Name of the longitude column in df DataFrame. Default is \"X\".\n",
    "        lat_column (str): Name of the latitude column in df DataFrame. Default is \"Y\".\n",
    "        output_file (str): The name of the output HTML file. Default is \"output.html\".\n",
    "    \"\"\"\n",
    "    # Start building the HTML content\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>GeoDataFrame HTML Page</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; }\n",
    "            .row { margin-bottom: 20px; padding: 10px; border: 1px solid #ddd; }\n",
    "            .id { font-size: 18px; font-weight: bold; }\n",
    "            .field { font-size: 14px; color: #555; }\n",
    "            .link { font-size: 14px; color: #007BFF; }\n",
    "            .image { margin-top: 10px; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    \"\"\"\n",
    "\n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "    (abusive_clearcuts_formated[\"Aire (ha)\"] >= 10)\n",
    "    & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] >= 2)\n",
    "    & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] >= 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"Aire >10Ha ET Natura2000 >2Ha ET pente>30% >2Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "    \n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "        (abusive_clearcuts_formated[\"Aire (ha)\"] >= 10)\n",
    "        & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] >= 2)\n",
    "        & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] < 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"Aire >10Ha ET Natura2000 >2Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "    \n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "        (abusive_clearcuts_formated[\"Aire (ha)\"] >= 10)\n",
    "        & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] < 2)\n",
    "        & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] >= 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"Aire >10Ha ET pente>30% >2Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "    \n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "        (abusive_clearcuts_formated[\"Aire (ha)\"] < 10)\n",
    "        & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] >= 2)\n",
    "        & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] >= 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"Natura2000 >2Ha ET pente>30% >2Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "    \n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "        (abusive_clearcuts_formated[\"Aire (ha)\"] >= 10)\n",
    "        & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] < 2)\n",
    "        & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] < 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"Aire >10Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "    \n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "        (abusive_clearcuts_formated[\"Aire (ha)\"] < 10)\n",
    "        & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] >= 2)\n",
    "        & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] < 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"Natura2000 >2Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "    \n",
    "    temp_df: gpd.GeoDataFrame = df[\n",
    "        (abusive_clearcuts_formated[\"Aire (ha)\"] < 10)\n",
    "        & (abusive_clearcuts_formated[\"Aire Natura2000 (ha)\"] < 2)\n",
    "        & (abusive_clearcuts_formated[\"Aire pente >30% (ha)\"] >= 2)\n",
    "    ]\n",
    "    html_content += generate_html_section(temp_df, \"pente>30% >2Ha\",\n",
    "                                          long_column, lat_column, output_path)\n",
    "\n",
    "\n",
    "    # Close the HTML content\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Write the HTML content to the output file\n",
    "    with open(output_path+output_file, \"w\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML page generated successfully: {output_path}{output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc23473-4165-4998-ac39-d0241ae24c09",
   "metadata": {},
   "source": [
    "# Format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a807cb-fe9a-4fe7-8957-0e241a1e8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_communes = communes[['code_insee', 'name']].rename({\"code_insee\": \"city_code_insee\", \"name\": \"city\"}, axis='columns')\n",
    "abusive_clearcuts_formated = pd.merge(left=abusive_clearcuts, right=temp_communes, how='left', on='city_code_insee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee16eaf-f90d-4664-8b9c-09d93c64bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_departements = departements[['code_insee', 'name']].rename({\"code_insee\": \"department_code_insee\", \"name\": \"departement\"}, axis='columns')\n",
    "abusive_clearcuts_formated = pd.merge(left=abusive_clearcuts_formated, right=temp_departements, how='left', on='department_code_insee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe74d00d-8d94-4ea1-a92d-81cb262b535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = abusive_clearcuts_formated.to_crs(epsg=4326).representative_point()\n",
    "abusive_clearcuts_formated['representative_point_x'] = centroids.x\n",
    "abusive_clearcuts_formated['representative_point_y'] = centroids.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7c5737-d421-4484-83cf-09ac825b7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "abusive_clearcuts_formated = abusive_clearcuts_formated[['date_min', 'date_max', 'days_delta', 'area_ha',\n",
    "'natura2000_area_ha', 'slope30_area_ha', 'city', 'departement', 'geometry', 'representative_point_x', 'representative_point_y']].rename(\n",
    "    {'date_min': 'Date de début',\n",
    "     'date_max': 'Date de fin',\n",
    "     'days_delta': 'Durée (j)',\n",
    "     'area_ha': 'Aire (ha)',\n",
    "     'natura2000_area_ha': 'Aire Natura2000 (ha)',\n",
    "     'slope30_area_ha': 'Aire pente >30% (ha)',\n",
    "     'city': 'Commune',\n",
    "     'departement': 'Département',\n",
    "     'representative_point_x': 'Longitude',\n",
    "     'representative_point_y': 'Latitude',\n",
    "    },\n",
    "    axis='columns'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738dba07-96d1-409a-9371-c47ca3b9d10b",
   "metadata": {},
   "source": [
    "# Format HTML output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67fbb185-cde0-4a17-b982-94c448671e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'html_output'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69f79f5d-29c6-446d-93ac-fd70cf391a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML page generated successfully: ./html_output/proposal.html\n",
      "CPU times: user 1min 49s, sys: 1.49 s, total: 1min 50s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_html_page(abusive_clearcuts_formated, long_column='Longitude',\n",
    "                   lat_column='Latitude', output_file='proposal.html', output_path='./html_output/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
